{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrRD0HH1GaVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "outputId": "11436e92-6cce-4c10-9f97-c772fb27c33b"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4-Tk-EUHh-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "cce6f8dd-fd22-4a3a-dee1-d7803a075a99"
      },
      "source": [
        "!wget http://www.manythings.org/anki/hin-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-18 10:45:52--  http://www.manythings.org/anki/hin-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126760 (124K) [application/zip]\n",
            "Saving to: ‘hin-eng.zip’\n",
            "\n",
            "\rhin-eng.zip           0%[                    ]       0  --.-KB/s               \rhin-eng.zip          40%[=======>            ]  50.41K   242KB/s               \rhin-eng.zip         100%[===================>] 123.79K   392KB/s    in 0.3s    \n",
            "\n",
            "2019-11-18 10:45:52 (392 KB/s) - ‘hin-eng.zip’ saved [126760/126760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azcwTgIwHmGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "#Read the zip file\n",
        "zf = zipfile.ZipFile('hin-eng.zip', 'r')\n",
        "#Extract data from zip file\n",
        "data = ''\n",
        "with zf.open('hin.txt') as readfile:\n",
        "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
        "    data += line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1f7gZTUMIO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "aaf78a68-f730-4ab8-f806-bdef801f164c"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2786"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jHYy53aHtFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a7710724-3bef-47f6-8aa1-ff2d2e44430d"
      },
      "source": [
        "data[400:500]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #6179123 (fastrizwaan)\\nHello!\\tनमस्'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NANnvnaIIulz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "138e779d-d47c-4a3b-f6d9-469517895184"
      },
      "source": [
        "#Split by newline character\n",
        "data = data.split('\\n')\n",
        "#Show some Data\n",
        "data[100:105]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I don't know.\\tमुझे नहीं पता।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #349064 (fatih) & #609376 (minshirui)\",\n",
              " \"I don't know.\\tमुझे नहीं मालूम।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #349064 (fatih) & #609377 (minshirui)\",\n",
              " 'I have a car.\\tमेरे पास एक गाड़ी है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #252272 (CK) & #477720 (minshirui)',\n",
              " 'I have a dog.\\tमेरे पास एक कुत्ता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #378502 (CK) & #443037 (minshirui)',\n",
              " 'I understand.\\tमैं समझता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433468 (CK) & #588495 (minshirui)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N8zXW5dI2x7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_text = [] #Initialize Source language list\n",
        "decoder_text = [] #Initialize Target language list\n",
        "#Iterate over data\n",
        "for line in data:\n",
        "  try:\n",
        "    in_txt, out_txt, a = line.split('\\t')\n",
        "    encoder_text.append(in_txt)\n",
        "    decoder_text.append('<start>'+out_txt+'<end>')\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-f18-o1JUzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "d589dd96-6079-4d82-ec2c-140331ba1e8e"
      },
      "source": [
        "encoder_text[100:105]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I don't know.\",\n",
              " \"I don't know.\",\n",
              " 'I have a car.',\n",
              " 'I have a dog.',\n",
              " 'I understand.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rYpgOzgJpTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "cb58874d-a025-4cbe-c0d5-5dbd30a50e2a"
      },
      "source": [
        "decoder_text[100:105]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start>मुझे नहीं पता।<end>',\n",
              " '<start>मुझे नहीं मालूम।<end>',\n",
              " '<start>मेरे पास एक गाड़ी है।<end>',\n",
              " '<start>मेरे पास एक कुत्ता है।<end>',\n",
              " '<start>मैं समझता हूँ।<end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrJIPqXJr1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b4cefafb-ff7d-4f6a-e7a9-07a63000294d"
      },
      "source": [
        "#Tokenizer for source language\n",
        "encoder_t = tf.keras.preprocessing.text.Tokenizer()\n",
        "encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences\n",
        "encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers\n",
        "encoder_seq[100:105] #Display some converted sentences"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 27, 43], [2, 27, 43], [2, 14, 6, 97], [2, 14, 6, 124], [2, 209]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSOal1msL2_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3422362c-74bc-43bf-89a0-bb7ba4b0db3a"
      },
      "source": [
        "#Maximum length of sentence\n",
        "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n",
        "print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n",
        "#Source language Vocablury\n",
        "encoder_vocab_size = len(encoder_t.word_index)\n",
        "print('Source language vocablury size: ', encoder_vocab_size)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sentence length for Source language:  22\n",
            "Source language vocablury size:  2376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls3_9h88MAnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenizer for target language, filters should not <start> and <end>\n",
        "#remove < and > used in Target language sequences\n",
        "decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n",
        "decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences tonumbers "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzg3yHWvMTj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c1b415de-9df0-4029-94b7-667f4ef5da01"
      },
      "source": [
        "#Maximum length of sentence\n",
        "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n",
        "print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n",
        "#Target language Vocablury\n",
        "decoder_vocab_size = len(decoder_t.word_index)\n",
        "print('Target language vocablury size: ', decoder_vocab_size)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sentence length for Target language:  25\n",
            "Target language vocablury size:  3317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-jLFvkDMWeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "59e84148-9f3b-458b-a437-a3d171144f80"
      },
      "source": [
        "#Target Language sentences\n",
        "print('Length for sentence number 100: ', len(decoder_seq[100]))\n",
        "print('Length for sentence number 2000: ', len(decoder_seq[2000]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length for sentence number 100:  3\n",
            "Length for sentence number 2000:  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XIc3VpXNQDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c81ec04d-9610-42ed-998f-f46a63d2cd80"
      },
      "source": [
        "#Target Language sentences\n",
        "print('Length for sentence number 100: ', len(encoder_seq[100]))\n",
        "print('Length for sentence number 2000: ', len(encoder_seq[2000]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length for sentence number 100:  3\n",
            "Length for sentence number 2000:  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkfgezYVNTOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Source sentences\n",
        "encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq,maxlen=max_encoder_seq_length, padding='pre')\n",
        "#Target Sentences\n",
        "decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, maxlen=max_decoder_seq_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUoRa6R4Noik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b35a8e0e-0229-4310-c382-78487848cb55"
      },
      "source": [
        "print('Source data shape: ', encoder_input_data.shape)\n",
        "print('Target data shape: ', decoder_input_data.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source data shape:  (2785, 22)\n",
            "Target data shape:  (2785, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5uerBOFNwdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#Initialize array\n",
        "decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n",
        "#Shift Target output by one word\n",
        "for i in range(decoder_input_data.shape[0]):\n",
        "  for j in range(1, decoder_input_data.shape[1]):\n",
        "    decoder_target_data[i][j-1] = decoder_input_data[i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2ILzTQgVkug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1], len(decoder_t.word_index)+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q_vAVcNWIAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build one hot encoded array\n",
        "for i in range(decoder_target_data.shape[0]):\n",
        "  for j in range(decoder_target_data.shape[1]):\n",
        "    decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],num_classes=len(decoder_t.word_index)+1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4mA_3qWVXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ab22ceeb-01fa-4b66-fe05-4178d665b1fe"
      },
      "source": [
        "decoder_target_one_hot.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2785, 25, 3318)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7RT6hFcWpxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "10cff78a-a40a-4b3a-f063-e9d66492535f"
      },
      "source": [
        "decoder_target_data.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2785, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btYUhdA0Wx2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fc2710a1-c03e-4db5-ffc4-31659632dc9f"
      },
      "source": [
        "len(decoder_t.word_index)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6igQy1ZHW2nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_word_decoder = dict((i,c) for c,i in decoder_t.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3AefYkMXT3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4c89908d-6c32-429c-988e-489a286349bd"
      },
      "source": [
        "int_to_word_decoder[5]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'से'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuR4iFBeXwln",
        "colab_type": "text"
      },
      "source": [
        "## Encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO-y-ML3XfAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define config parameters\n",
        "encoder_embedding_size = 50\n",
        "decoder_embedding_size = 50\n",
        "rnn_units = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVNhYRogYLDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "bbe2776e-1226-4fce-e2ee-2db50babb7f4"
      },
      "source": [
        "#Input Layer\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "#Embedding layer\n",
        "encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, encoder_embedding_size)\n",
        "#Get embedding layer output by feeding inputs\n",
        "encoder_embedding_output = encoder_embedding(encoder_inputs)\n",
        "#LSTM Layer and its output\n",
        "x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n",
        "#Build a list to feed Decoder\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlnboMr7ZHo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = tf.keras.Input(shape=(None,))\n",
        "#Decoder Embedding layer\n",
        "decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n",
        "#Embedding layer output\n",
        "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
        "#Decoder RNN\n",
        "decoder_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "#Decoder RNN Output, State initialization from Encoder states\n",
        "\n",
        "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
        "x,_,_ = decoder_rnn(decoder_embedding_output, initial_state=encoder_states)\n",
        "#Output Layer\n",
        "decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n",
        "#Output of Dense layer\n",
        "decoder_outputs = decoder_dense(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV6S4p5FbKSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n",
        "                                decoder_outputs) #Output of the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IJvdtlSbT61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e484ad4f-df4b-448b-b1de-91e2983000cf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 50)     118850      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     165900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 314368      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  314368      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 3318)   852726      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,766,212\n",
            "Trainable params: 1,766,212\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-OdVoHobX_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-1xZU47br1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "b1e415fa-1c2a-4b71-b8e2-ffcc5a183f63"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot, batch_size=64, epochs=5, validation_split=0.2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 2228 samples, validate on 557 samples\n",
            "Epoch 1/5\n",
            "2228/2228 [==============================] - 10s 4ms/sample - loss: 3.7815 - val_loss: 2.9203\n",
            "Epoch 2/5\n",
            "2228/2228 [==============================] - 4s 2ms/sample - loss: 1.4894 - val_loss: 2.9437\n",
            "Epoch 3/5\n",
            "2228/2228 [==============================] - 4s 2ms/sample - loss: 1.4541 - val_loss: 2.8873\n",
            "Epoch 4/5\n",
            "2228/2228 [==============================] - 4s 2ms/sample - loss: 1.4311 - val_loss: 2.8995\n",
            "Epoch 5/5\n",
            "2228/2228 [==============================] - 4s 2ms/sample - loss: 1.3941 - val_loss: 2.8817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f65d544ed68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AIKZkyub04X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./seq2seq_training_translation.hd5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHBPH9RdcOkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3slm7tAdoyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hidden state input\n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n",
        "#Cell state input\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n",
        "#Putting it together\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsVRtdUyeCoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get Embedding layer output\n",
        "x = decoder_embedding(decoder_inputs)\n",
        "#We will use the layer which we trained earlier\n",
        "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n",
        "#Why do we need this?\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5pWqm6deRZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_outputs=decoder_dense(rnn_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgtkPXWResNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs, #Model inputs\n",
        " [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9vDx9boe3Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sentence(input_sequence):\n",
        "\n",
        " #Get the encoder state values - Sentence embedding\n",
        "  decoder_initial_states_value = encoder_model.predict(input_seq)\n",
        "\n",
        " #Build a sequence with '<start>' - starting sequence for Decoder\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0][0] = decoder_t.word_index['<start>']\n",
        "\n",
        " #flag to check if prediction should be stopped\n",
        "  stop_loop = False\n",
        "\n",
        "  #Initialize predicted sentence\n",
        "  predicted_sentence = ''\n",
        "  i = 0\n",
        " #start the loop\n",
        "  while not stop_loop:\n",
        "\n",
        "    predicted_outputs, h, c = decoder_model.predict([target_seq] + decoder_initial_states_value)\n",
        "    #Get the predicted word index with highest probability\n",
        "    predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
        "    if(predicted_output ==0):\n",
        "      predicted_word = ' '\n",
        "    #Get the predicted word from predicter index\n",
        "    else:\n",
        "      predicted_word = int_to_word_decoder[predicted_output]\n",
        "    \n",
        "    #Check if prediction should stop\n",
        "    if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
        "      stop_loop = True\n",
        "      continue\n",
        "    #Updated predicted sentence\n",
        "    if (len(predicted_sentence) == 0):\n",
        "      predicted_sentence = predicted_word\n",
        "    else:\n",
        "      predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
        "\n",
        "    #Update target_seq to be the predicted word index\n",
        "    target_seq[0][0] = predicted_output\n",
        "\n",
        "    #Update initial states value for decoder\n",
        "    decoder_initial_states_value = [h,c]\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Tp1ApFf_vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "6c43aaae-b34e-4dfd-bf47-6c0abac73a86"
      },
      "source": [
        "start_num = np.random.randint(0, high=len(encoder_text)-10)\n",
        "\n",
        "for i in range(start_num, start_num+1):\n",
        "  input_seq = encoder_input_data[i:i+1]\n",
        "  predicted_sentences = decode_sentence(input_seq)\n",
        "  print('------------')\n",
        "  print('Input sentence: ', encoder_text[i])\n",
        "  print('Predicted sentences: ', predicted_sentences)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------\n",
            "Input sentence:  He saw a dog near the door.\n",
            "Predicted sentences:  में में में                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k639Sm2ZmiUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}